name: Crawl Data

on:
  schedule:
    - cron: '0 4 * * *'  # Run daily at 12:00 PM UTC+8 (4:00 AM UTC)
  push:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: crawl
  cancel-in-progress: false

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout main branch
        uses: actions/checkout@v4

      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgbm-dev \
            libxshmfence-dev \
            libglu1-mesa-dev \
            libx11-dev

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
          cache: 'npm'

      - name: Configure npm
        run: |
          # 跳过 Chromium 下载（使用系统已安装版本）
          export PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
      
      - name: Install Base Dependencies
        run: npm ci --omit=optional --ignore-scripts --no-audit --no-fund

      - name: Install Puppeteer Dependencies
        run: |
          # 单独安装 puppeteer 核心
          npm install puppeteer-core@21.7.0
          # 链接系统 Chromium
          ln -s /usr/bin/chromium-browser ./node_modules/puppeteer-core/.local-chromium/linux-*/chrome-linux/chrome

      - name: Install ESBuild
        run: npm rebuild esbuild --platform=linux --arch=x64

      - name: Crawl data
        run: npm run start

      - name: Checkout result branch
        uses: actions/checkout@v4
        with:
          ref: result
          path: result-branch

      - name: Sync crawled data
        run: |
          rsync -av --delete result/ result-branch/

      - name: Commit and push results
        working-directory: result-branch
        run: |
          git config user.name github-actions
          git config user.email github-actions@github.com
          git add .
          git commit -m "$(TZ=Asia/Shanghai date +"%Y-%m-%d %H:%M:%S")"
          git push origin result
